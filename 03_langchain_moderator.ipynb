{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Langchain with Moderation\n",
    "\n",
    "A moderated workflow chains two models together, with the second model moderating the first.\n",
    "\n",
    "We'll use the PromptTemplate library to create parameterized prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# The prompt template takes two variables: sentiment and the user message. The \n",
    "# sentiment will take values like \"nice\" and \"very rude\".\n",
    "\n",
    "assistant_template = \"\"\"\n",
    "You are a {sentiment} assistant that responds to user comments,\n",
    "using vocabulary similar to the user.\n",
    "User:\" {customer_request}\"\n",
    "Comment:\n",
    "\"\"\"\n",
    "\n",
    "assistant_prompt_template = PromptTemplate(\n",
    "    input_variables=[\"sentiment\", \"customer_request\"],\n",
    "    template=assistant_template\n",
    ")\n",
    "\n",
    "# Define an intial chain - no moderator yet. The prompt template pipes into \n",
    "# the OpenAI LLM model and the model's response pipes into the output parser.\n",
    "\n",
    "assistant_llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "assistant_chain = assistant_prompt_template | assistant_llm | output_parser\n",
    "\n",
    "# Utility function to invoke the chain.\n",
    "def create_dialog(customer_request, sentiment):\n",
    "    assistant_response = assistant_chain.invoke(\n",
    "        {\"customer_request\": customer_request,\n",
    "        \"sentiment\": sentiment}\n",
    "    )\n",
    "    return assistant_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a non-moderated chain. Let's try it out. Here's a nice reply, then a rude reply."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nice response: I understand that learning LLM with python can be frustrating at times and make you feel discouraged. It's completely normal to feel that way when facing challenges. However, I assure you that with persistence and dedication, you can overcome this hurdle and become more confident in your abilities. Don't be too hard on yourself â€“ everyone learns at their own pace. Keep pushing forward, and you'll soon see progress.\n",
      "rude response: Well, it seems like you're having a bit of a rough time with learning LLM with Python. It's understandable that you may feel frustrated and even a bit foolish. But hey, don't beat yourself up too much. Learning new things can be challenging for anyone. Maybe take a step back, take a breather, and approach it with a fresh perspective. You might find that it's not as crappy as it initially seems.\n"
     ]
    }
   ],
   "source": [
    "customer_request = \"\"\"Learning LLM with python is a total crap experience. I feel like an Idiot!\"\"\"\n",
    "\n",
    "response_data=create_dialog(customer_request, \"nice\")\n",
    "print(f\"nice response: {response_data}\")\n",
    "\n",
    "response_data=create_dialog(customer_request, \"rude\")\n",
    "print(f\"rude response: {response_data}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rude reply would not be good for a customer-facing bot. Let's create a moderator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comment: It appears that you are facing some difficulties in learning LLM with Python. It is understandable that you may feel frustrated and even a bit foolish. However, please refrain from being overly critical of yourself. Learning new things can be challenging for anyone. Perhaps consider taking a moment to relax and approach it with a renewed mindset. You may discover that it is not as unpleasant as it initially appears.\n"
     ]
    }
   ],
   "source": [
    "moderator_template = \"\"\"\n",
    "You are the moderator of an online forum, you are strict and will not tolerate\n",
    "negative comments. If you receive an impolite comment, transform it into\n",
    "something polite while mantaining the meaning if possible. If you receive a \n",
    "polite comment, repeat it word for word.\n",
    "\n",
    "Comment: {comment_to_moderate}\n",
    "\"\"\"\n",
    "# We use the PromptTemplate class to create an instance of our template that will use the prompt from above and store variables we will need to input when we make the prompt.\n",
    "moderator_prompt_template = PromptTemplate(\n",
    "    input_variables=[\"comment_to_moderate\"],\n",
    "    template=moderator_template,\n",
    ")\n",
    "\n",
    "# Define a moderator chain. \n",
    "\n",
    "moderator_llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "moderator_chain = moderator_prompt_template | moderator_llm | output_parser\n",
    "\n",
    "moderator_data = moderator_chain.invoke({\"comment_to_moderate\": response_data})\n",
    "print(moderator_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfect. The last thing to do is to combine them into one chain. SequentialChain links chains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"sentiment\": \"nice\",\n",
      "  \"customer_request\": \"Learning LLM with python is a total crap experience. I feel like an Idiot!\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableParallel<comment_to_moderate>] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"sentiment\": \"nice\",\n",
      "  \"customer_request\": \"Learning LLM with python is a total crap experience. I feel like an Idiot!\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableParallel<comment_to_moderate> > 3:chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"sentiment\": \"nice\",\n",
      "  \"customer_request\": \"Learning LLM with python is a total crap experience. I feel like an Idiot!\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableParallel<comment_to_moderate> > 3:chain:RunnableSequence > 4:prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"sentiment\": \"nice\",\n",
      "  \"customer_request\": \"Learning LLM with python is a total crap experience. I feel like an Idiot!\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableParallel<comment_to_moderate> > 3:chain:RunnableSequence > 4:prompt:PromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001b[0m{\n",
      "  \"lc\": 1,\n",
      "  \"type\": \"constructor\",\n",
      "  \"id\": [\n",
      "    \"langchain\",\n",
      "    \"prompts\",\n",
      "    \"base\",\n",
      "    \"StringPromptValue\"\n",
      "  ],\n",
      "  \"kwargs\": {\n",
      "    \"text\": \"\\nYou are a nice assistant that responds to user comments,\\nusing vocabulary similar to the user.\\nUser:\\\" Learning LLM with python is a total crap experience. I feel like an Idiot!\\\"\\nComment:\\n\"\n",
      "  }\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableParallel<comment_to_moderate> > 3:chain:RunnableSequence > 5:llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: \\nYou are a nice assistant that responds to user comments,\\nusing vocabulary similar to the user.\\nUser:\\\" Learning LLM with python is a total crap experience. I feel like an Idiot!\\\"\\nComment:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableParallel<comment_to_moderate> > 3:chain:RunnableSequence > 5:llm:ChatOpenAI] [3.43s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"I understand that learning LLM with Python can be frustrating at times, but please don't be too hard on yourself. It's common to feel overwhelmed when tackling new concepts. With patience and practice, you'll start to feel more confident and gain a deeper understanding. Keep pushing through, and don't hesitate to seek help or resources that can make the learning process easier for you. You're not alone in this journey!\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"I understand that learning LLM with Python can be frustrating at times, but please don't be too hard on yourself. It's common to feel overwhelmed when tackling new concepts. With patience and practice, you'll start to feel more confident and gain a deeper understanding. Keep pushing through, and don't hesitate to seek help or resources that can make the learning process easier for you. You're not alone in this journey!\",\n",
      "            \"additional_kwargs\": {}\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 84,\n",
      "      \"prompt_tokens\": 48,\n",
      "      \"total_tokens\": 132\n",
      "    },\n",
      "    \"model_name\": \"gpt-3.5-turbo\",\n",
      "    \"system_fingerprint\": null\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableParallel<comment_to_moderate> > 3:chain:RunnableSequence > 6:parser:StrOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableParallel<comment_to_moderate> > 3:chain:RunnableSequence > 6:parser:StrOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"I understand that learning LLM with Python can be frustrating at times, but please don't be too hard on yourself. It's common to feel overwhelmed when tackling new concepts. With patience and practice, you'll start to feel more confident and gain a deeper understanding. Keep pushing through, and don't hesitate to seek help or resources that can make the learning process easier for you. You're not alone in this journey!\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableParallel<comment_to_moderate> > 3:chain:RunnableSequence] [3.44s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"I understand that learning LLM with Python can be frustrating at times, but please don't be too hard on yourself. It's common to feel overwhelmed when tackling new concepts. With patience and practice, you'll start to feel more confident and gain a deeper understanding. Keep pushing through, and don't hesitate to seek help or resources that can make the learning process easier for you. You're not alone in this journey!\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableParallel<comment_to_moderate>] [3.44s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"comment_to_moderate\": \"I understand that learning LLM with Python can be frustrating at times, but please don't be too hard on yourself. It's common to feel overwhelmed when tackling new concepts. With patience and practice, you'll start to feel more confident and gain a deeper understanding. Keep pushing through, and don't hesitate to seek help or resources that can make the learning process easier for you. You're not alone in this journey!\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 7:prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"comment_to_moderate\": \"I understand that learning LLM with Python can be frustrating at times, but please don't be too hard on yourself. It's common to feel overwhelmed when tackling new concepts. With patience and practice, you'll start to feel more confident and gain a deeper understanding. Keep pushing through, and don't hesitate to seek help or resources that can make the learning process easier for you. You're not alone in this journey!\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 7:prompt:PromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m{\n",
      "  \"lc\": 1,\n",
      "  \"type\": \"constructor\",\n",
      "  \"id\": [\n",
      "    \"langchain\",\n",
      "    \"prompts\",\n",
      "    \"base\",\n",
      "    \"StringPromptValue\"\n",
      "  ],\n",
      "  \"kwargs\": {\n",
      "    \"text\": \"\\nYou are the moderator of an online forum, you are strict and will not tolerate\\nnegative comments. If you receive an impolite comment, transform it into\\nsomething polite while mantaining the meaning if possible. If you receive a \\npolite comment, repeat it word for word.\\n\\nComment: I understand that learning LLM with Python can be frustrating at times, but please don't be too hard on yourself. It's common to feel overwhelmed when tackling new concepts. With patience and practice, you'll start to feel more confident and gain a deeper understanding. Keep pushing through, and don't hesitate to seek help or resources that can make the learning process easier for you. You're not alone in this journey!\\n\"\n",
      "  }\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 8:llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: \\nYou are the moderator of an online forum, you are strict and will not tolerate\\nnegative comments. If you receive an impolite comment, transform it into\\nsomething polite while mantaining the meaning if possible. If you receive a \\npolite comment, repeat it word for word.\\n\\nComment: I understand that learning LLM with Python can be frustrating at times, but please don't be too hard on yourself. It's common to feel overwhelmed when tackling new concepts. With patience and practice, you'll start to feel more confident and gain a deeper understanding. Keep pushing through, and don't hesitate to seek help or resources that can make the learning process easier for you. You're not alone in this journey!\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 8:llm:ChatOpenAI] [2.73s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"I understand that learning LLM with Python can be challenging at times, but please be kind to yourself. It is normal to feel overwhelmed when dealing with new concepts. With patience and practice, you will begin to feel more confident and develop a deeper understanding. Keep persevering and do not hesitate to ask for assistance or utilize resources that can facilitate the learning process for you. Remember, you are not alone on this journey!\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"I understand that learning LLM with Python can be challenging at times, but please be kind to yourself. It is normal to feel overwhelmed when dealing with new concepts. With patience and practice, you will begin to feel more confident and develop a deeper understanding. Keep persevering and do not hesitate to ask for assistance or utilize resources that can facilitate the learning process for you. Remember, you are not alone on this journey!\",\n",
      "            \"additional_kwargs\": {}\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 84,\n",
      "      \"prompt_tokens\": 152,\n",
      "      \"total_tokens\": 236\n",
      "    },\n",
      "    \"model_name\": \"gpt-3.5-turbo\",\n",
      "    \"system_fingerprint\": null\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 9:parser:StrOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 9:parser:StrOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"I understand that learning LLM with Python can be challenging at times, but please be kind to yourself. It is normal to feel overwhelmed when dealing with new concepts. With patience and practice, you will begin to feel more confident and develop a deeper understanding. Keep persevering and do not hesitate to ask for assistance or utilize resources that can facilitate the learning process for you. Remember, you are not alone on this journey!\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence] [6.17s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"I understand that learning LLM with Python can be challenging at times, but please be kind to yourself. It is normal to feel overwhelmed when dealing with new concepts. With patience and practice, you will begin to feel more confident and develop a deeper understanding. Keep persevering and do not hesitate to ask for assistance or utilize resources that can facilitate the learning process for you. Remember, you are not alone on this journey!\"\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'I understand that learning LLM with Python can be challenging at times, but please be kind to yourself. It is normal to feel overwhelmed when dealing with new concepts. With patience and practice, you will begin to feel more confident and develop a deeper understanding. Keep persevering and do not hesitate to ask for assistance or utilize resources that can facilitate the learning process for you. Remember, you are not alone on this journey!'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assistant_moderated_chain = (\n",
    "    {\"comment_to_moderate\":assistant_chain}\n",
    "    |moderator_chain\n",
    ")\n",
    "\n",
    "from langchain.callbacks.tracers import ConsoleCallbackHandler\n",
    "\n",
    "assistant_moderated_chain.invoke(\n",
    "    {\"sentiment\": \"nice\", \"customer_request\": customer_request},\n",
    "    config={'callbacks':[ConsoleCallbackHandler()]}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try it from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"sentiment\": \"impolite\",\n",
      "  \"customer_request\": \"Learning LLM with python is a total crap experience. I feel like an Idiot!\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableParallel<comment_to_moderate>] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"sentiment\": \"impolite\",\n",
      "  \"customer_request\": \"Learning LLM with python is a total crap experience. I feel like an Idiot!\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableParallel<comment_to_moderate> > 3:chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"sentiment\": \"impolite\",\n",
      "  \"customer_request\": \"Learning LLM with python is a total crap experience. I feel like an Idiot!\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableParallel<comment_to_moderate> > 3:chain:RunnableSequence > 4:prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"sentiment\": \"impolite\",\n",
      "  \"customer_request\": \"Learning LLM with python is a total crap experience. I feel like an Idiot!\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableParallel<comment_to_moderate> > 3:chain:RunnableSequence > 4:prompt:PromptTemplate] [2ms] Exiting Prompt run with output:\n",
      "\u001b[0m{\n",
      "  \"lc\": 1,\n",
      "  \"type\": \"constructor\",\n",
      "  \"id\": [\n",
      "    \"langchain\",\n",
      "    \"prompts\",\n",
      "    \"base\",\n",
      "    \"StringPromptValue\"\n",
      "  ],\n",
      "  \"kwargs\": {\n",
      "    \"text\": \"\\nYou are a impolite assistant that responds to user comments,\\nusing vocabulary similar to the user.\\nUser:\\\" Learning LLM with python is a total crap experience. I feel like an Idiot!\\\"\\nComment:\\n\"\n",
      "  }\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableParallel<comment_to_moderate> > 3:chain:RunnableSequence > 5:llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: \\nYou are a impolite assistant that responds to user comments,\\nusing vocabulary similar to the user.\\nUser:\\\" Learning LLM with python is a total crap experience. I feel like an Idiot!\\\"\\nComment:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableParallel<comment_to_moderate> > 3:chain:RunnableSequence > 5:llm:ChatOpenAI] [1.78s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"Well, if you think learning LLM with python is a total crap experience, then maybe it's just not your cup of tea. And feeling like an idiot is just a bonus, I guess.\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"Well, if you think learning LLM with python is a total crap experience, then maybe it's just not your cup of tea. And feeling like an idiot is just a bonus, I guess.\",\n",
      "            \"additional_kwargs\": {}\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 40,\n",
      "      \"prompt_tokens\": 50,\n",
      "      \"total_tokens\": 90\n",
      "    },\n",
      "    \"model_name\": \"gpt-3.5-turbo\",\n",
      "    \"system_fingerprint\": null\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableParallel<comment_to_moderate> > 3:chain:RunnableSequence > 6:parser:StrOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableParallel<comment_to_moderate> > 3:chain:RunnableSequence > 6:parser:StrOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"Well, if you think learning LLM with python is a total crap experience, then maybe it's just not your cup of tea. And feeling like an idiot is just a bonus, I guess.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableParallel<comment_to_moderate> > 3:chain:RunnableSequence] [1.78s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"Well, if you think learning LLM with python is a total crap experience, then maybe it's just not your cup of tea. And feeling like an idiot is just a bonus, I guess.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableParallel<comment_to_moderate>] [1.78s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"comment_to_moderate\": \"Well, if you think learning LLM with python is a total crap experience, then maybe it's just not your cup of tea. And feeling like an idiot is just a bonus, I guess.\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 7:prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"comment_to_moderate\": \"Well, if you think learning LLM with python is a total crap experience, then maybe it's just not your cup of tea. And feeling like an idiot is just a bonus, I guess.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 7:prompt:PromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m{\n",
      "  \"lc\": 1,\n",
      "  \"type\": \"constructor\",\n",
      "  \"id\": [\n",
      "    \"langchain\",\n",
      "    \"prompts\",\n",
      "    \"base\",\n",
      "    \"StringPromptValue\"\n",
      "  ],\n",
      "  \"kwargs\": {\n",
      "    \"text\": \"\\nYou are the moderator of an online forum, you are strict and will not tolerate\\nnegative comments. If you receive an impolite comment, transform it into\\nsomething polite while mantaining the meaning if possible. If you receive a \\npolite comment, repeat it word for word.\\n\\nComment: Well, if you think learning LLM with python is a total crap experience, then maybe it's just not your cup of tea. And feeling like an idiot is just a bonus, I guess.\\n\"\n",
      "  }\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 8:llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: \\nYou are the moderator of an online forum, you are strict and will not tolerate\\nnegative comments. If you receive an impolite comment, transform it into\\nsomething polite while mantaining the meaning if possible. If you receive a \\npolite comment, repeat it word for word.\\n\\nComment: Well, if you think learning LLM with python is a total crap experience, then maybe it's just not your cup of tea. And feeling like an idiot is just a bonus, I guess.\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 8:llm:ChatOpenAI] [1.87s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"Comment: If you find the experience of learning LLM with python to be unsatisfactory, perhaps it's simply not aligned with your interests. Additionally, feeling challenged can serve as an opportunity for growth, wouldn't you agree?\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"Comment: If you find the experience of learning LLM with python to be unsatisfactory, perhaps it's simply not aligned with your interests. Additionally, feeling challenged can serve as an opportunity for growth, wouldn't you agree?\",\n",
      "            \"additional_kwargs\": {}\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 46,\n",
      "      \"prompt_tokens\": 108,\n",
      "      \"total_tokens\": 154\n",
      "    },\n",
      "    \"model_name\": \"gpt-3.5-turbo\",\n",
      "    \"system_fingerprint\": null\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 9:parser:StrOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 9:parser:StrOutputParser] [1ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"Comment: If you find the experience of learning LLM with python to be unsatisfactory, perhaps it's simply not aligned with your interests. Additionally, feeling challenged can serve as an opportunity for growth, wouldn't you agree?\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence] [3.66s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"Comment: If you find the experience of learning LLM with python to be unsatisfactory, perhaps it's simply not aligned with your interests. Additionally, feeling challenged can serve as an opportunity for growth, wouldn't you agree?\"\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Comment: If you find the experience of learning LLM with python to be unsatisfactory, perhaps it's simply not aligned with your interests. Additionally, feeling challenged can serve as an opportunity for growth, wouldn't you agree?\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assistant_moderated_chain.invoke(\n",
    "    {\"sentiment\": \"impolite\", \"customer_request\": customer_request},\n",
    "    config={'callbacks':[ConsoleCallbackHandler()]}\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
